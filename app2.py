import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import gaussian_kde
from functools import reduce
import lightgbm as lgb
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    log_loss,
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve,
    auc,
    matthews_corrcoef
)

st.set_page_config(layout='wide', page_title='ãƒ‡ãƒ¼ã‚¿åˆ†æEDA', page_icon='ğŸ“Š')

# å±æ€§ãŒå­˜åœ¨ã—ãªã„å ´åˆã«åˆæœŸåŒ–
keys_defaults = [
    ('df_train', None),
    ('df_test', None),
    ('target', None),
    ('features', None),
    ('default_df_train', None),
    ('default_df_test', None),
    ('default_target', None),
    ('default_features', None)
]

# ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ã£ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–
for key, default_value in keys_defaults:
    if key not in st.session_state:
        st.session_state[key] = default_value

# datasetã®åˆæœŸåŒ–
if st.session_state.df_train is not None and st.session_state.df_test is not None:
    df_train = st.session_state.df_train
    df_test = st.session_state.df_test
    target = st.session_state.target
    features = st.session_state.features
else:
    df_train = pd.read_csv('dataset/titanic_data/titanic_train.csv')
    df_test = pd.read_csv('dataset/titanic_data/titanic_test.csv')
    target = 'Survived'
    df_features = df_train.drop(['PassengerId', 'Survived'], axis=1)
    features = df_features.columns.tolist()
    st.session_state.default_df_train = df_train
    st.session_state.default_df_test = df_test
    st.session_state.default_target = target
    st.session_state.default_features = features

# dataseté–¢æ•°
def dataset():
    if st.session_state.df_train is not None:
        st.sidebar.info('ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®TrainDataã‚’ä½¿ç”¨ä¸­')
    else:
        st.sidebar.warning('ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®TrainDataã‚’ä½¿ç”¨ä¸­')

    if st.session_state.df_test is not None:
        st.sidebar.info('ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®TestDataã‚’ä½¿ç”¨ä¸­')
    else:
        st.sidebar.warning("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®TestDataã‚’ä½¿ç”¨ä¸­")

    if st.session_state.target is not None:
        st.sidebar.info(f'ç›®çš„å¤‰æ•°: {st.session_state.target}')
    else:
        st.sidebar.warning(f'ç›®çš„å¤‰æ•°: "Survived"')
        
    st.sidebar.markdown('---')

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.title('ãƒ‡ãƒ¼ã‚¿åˆ†æEDA (åˆ†é¡)')

home = 'ãƒ›ãƒ¼ãƒ '
loading_data = 'ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™'
data_summary = 'ãƒ‡ãƒ¼ã‚¿æ¦‚è¦'
each_feature = 'å„ç‰¹å¾´é‡ã®è¦ç´„'
model = 'ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰'

selection = [home, loading_data, data_summary, each_feature, model]
choice = st.sidebar.selectbox('ãƒ¡ãƒ‹ãƒ¥ãƒ¼', selection, key='menu')

# ãƒ›ãƒ¼ãƒ ---------------------
if choice == home:
    home_tab1, home_tab2 = st.tabs(['ã‚¢ãƒ—ãƒªæ¦‚è¦','ã‚¬ã‚¤ãƒ‰'])

    #ã‚¢ãƒ—ãƒªæ¦‚è¦
    with home_tab1:
        st.markdown('<div style="text-align: right;">', unsafe_allow_html=True)
        st.image("img/EDA.jpg", width=int(1200 * 0.2))
        st.markdown('</div>', unsafe_allow_html=True)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown(
                '''
                <div style="text-align: left;"><h2 style="font-size: 24px;">ã‚¢ãƒ—ãƒªæ¦‚è¦</h2>
                ã“ã®ã‚¢ãƒ—ãƒªã¯ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®åˆ†é¡ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹EDAã‚’åŠ©ã‘ã¾ã™ã€‚<br>
                ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ãƒ»å„ç‰¹å¾´é‡ã®æŠŠæ¡ã€ç‰¹å¾´é‡åŒå£«ã®é–¢ä¿‚æ€§ã‚’è¡¨ãƒ»ã‚°ãƒ©ãƒ•åŒ–ã—ã¾ã™ã€‚<br>
                ã¾ãŸã€LGBMã§ã®å˜ç´”ãªãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ãŒã§ãã€å­¦ç¿’ãƒ»äºˆæ¸¬ã‚’çµŒã¦ç°¡å˜ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚<br>
                <br>
                <div style="text-align: right;">2024.8.14</div><br>
                </div>
                ''', unsafe_allow_html=True)
            
        st.info('å½“ã‚¢ãƒ—ãƒªã¯Kaggleã§æä¾›ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æƒ³å®šã—ã¦ä½œæˆã—ã¾ã—ãŸã€‚')

    # ã‚¬ã‚¤ãƒ‰
    with home_tab2:        
        slides = [f'img/guide/slide{i}.JPG' for i in range(1, 8)]
        for slide in slides:
            st.image(slide, caption='', use_column_width=True)

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™--------------
if choice == loading_data:

    dataset()

    st.markdown('<h2 style="font-size: 24px;">ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h2>', unsafe_allow_html=True)

    col1, col2 = st.columns(2)
    with col1:

        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿å‰²åˆã‚’è¨­å®šã§ãã‚‹ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
        sample_ratio = st.slider(
            'ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿å‰²åˆã‚’è¨­å®š (%)', 
            min_value=10, max_value=100, step=10, value=100
        ) / 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã‚’å°æ•°ã«å¤‰æ›

        st.markdown('**å­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**')
        uploaded_train_file = st.file_uploader('å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿(ä»¥é™TrainData)', type=['csv'])
        st.markdown('<br>', unsafe_allow_html=True)
        st.markdown('**äºˆæ¸¬ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**')
        uploaded_test_file = st.file_uploader('äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿(ä»¥é™TestData)', type=['csv'])
        st.markdown('<br>', unsafe_allow_html=True)
    
    with col2:
        # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        if uploaded_train_file is not None:
            df_train = pd.read_csv(uploaded_train_file)
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šã•ã‚ŒãŸå‰²åˆã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            if sample_ratio < 1.0:
                df_train = df_train.sample(frac=sample_ratio, random_state=42)
            
            st.info(f'ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸğŸ‘Œ (è¨­å®šèª­è¾¼å‰²åˆ:{int(sample_ratio * 100)}%)')
            st.session_state.df_train = df_train
        else:
            st.warning('ç¾åœ¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚')

        # æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        if uploaded_test_file is not None:
            df_test = pd.read_csv(uploaded_test_file)
        
            # ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šã•ã‚ŒãŸå‰²åˆã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            if sample_ratio < 1.0:
                df_test = df_test.sample(frac=sample_ratio, random_state=42)
            
            st.info(f'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸğŸ‘Œ (è¨­å®šèª­è¾¼å‰²åˆ:{int(sample_ratio * 100)}%)')
            st.session_state.df_test = df_test
            
        else:
            st.warning('ç¾åœ¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚')

        # ç›®çš„å¤‰æ•°ã¨èª¬æ˜å¤‰æ•°ã®è¨­å®š
        if uploaded_train_file is not None:
            st.error('ç›®çš„å¤‰æ•°ãƒ»èª¬æ˜å¤‰æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚')
            
            feature_target = df_train.columns.tolist()
            # ç›®çš„å¤‰æ•°ã®é¸æŠ
            target = st.selectbox('ç›®çš„å¤‰æ•°', feature_target, index=0)
            
            features_drop_target = [feature for feature in feature_target if feature != target]
            # èª¬æ˜å¤‰æ•°ã®é¸æŠ
            features = st.multiselect('èª¬æ˜å¤‰æ•°', features_drop_target, features_drop_target)

            st.session_state.target = target
            st.session_state.features = features
            
        else:
            st.warning('ç›®çš„å¤‰æ•°ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã™ã€‚')
            


#ãƒ‡ãƒ¼ã‚¿æ¦‚è¦------------------------------------------
if choice == data_summary:
    dataset()

    tab1, tab2, tab3, tab4 = st.tabs(['ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª', 'ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„', 'ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', 'ãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆ']) 

    #ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    with tab1:
        st.markdown('<h2 style="font-size: 24px;">ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª</h2>', unsafe_allow_html=True)
        st.markdown('<h3 style="font-size: 20px;">TrainData</h3>', unsafe_allow_html=True)
        if len(df_train) > 1000:
            st.write('1000è¡Œã‚’è¶…ãˆã‚‹ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚æœ€åˆã®100è¡Œã®ã¿è¡¨ç¤ºã—ã¾ã™ã€‚')
            st.dataframe(df_train.head(100))
        else:
            st.dataframe(df_train)

        st.markdown('---')
        
        st.markdown('<h3 style="font-size: 20px;">TestData</h3>', unsafe_allow_html=True)
        if len(df_test) > 1000:
            st.write('1000è¡Œã‚’è¶…ãˆã‚‹ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚æœ€åˆã®100è¡Œã®ã¿è¡¨ç¤ºã—ã¾ã™ã€‚')
            st.dataframe(df_test.head(100))
        else:
            st.dataframe(df_test)

    #ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„
    with tab2:
        st.markdown('<h2 style="font-size: 24px;">ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„</h2>', unsafe_allow_html=True)
        tab2_col1, tab2_col2 = st.columns(2)
        
        def dataset_overview(df):
            column_names = df.columns
            data_types = df.dtypes
            missing_values = df.isnull().sum()
            total_rows = len(df)
            missing_percent = (missing_values / total_rows) * 100
            unique_counts = [df[col].nunique() for col in column_names]

            summary = pd.DataFrame({
                'Dtype': data_types,
                'æ¬ æå€¤': missing_values,
                'æ¬ æå€¤å‰²åˆ(%)': np.floor(missing_percent).astype(int),
                'ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°': unique_counts
            })
            return st.dataframe(summary)
        
        with tab2_col1:
            st.markdown('<h3 style="font-size: 20px;">TrainData</h3>', unsafe_allow_html=True)
            st.write(f'{df_train.shape[0]}è¡Œ Ã— {df_train.shape[1]}åˆ—')
            dataset_overview(df_train)

        with tab2_col2:
            st.markdown('<h3 style="font-size: 20px;">TestData</h3>', unsafe_allow_html=True)
            st.write(f'{df_test.shape[0]}è¡Œ Ã— {df_test.shape[1]}åˆ—')
            dataset_overview(df_test)

    with tab3:
        original_labels = {col: df_train[col].unique() for col in df_train.columns if df_train[col].dtype == 'object'}

        # ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        label_encoders = {}
        encoded_df = df_train.copy()
        for col in encoded_df.columns:
            if encoded_df[col].dtype == 'object':
                le = LabelEncoder()
                encoded_df[col] = le.fit_transform(encoded_df[col])
                label_encoders[col] = le

        options = st.multiselect(
            'ç‰¹å¾´é‡ã®é¸æŠ',
            [target] + features,
            [target] + features,
            key='heatmap_select_features'
        )

        st.header("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
        if st.button('å®Ÿè¡Œ', key='unique_key_1'):
            with st.spinner('Generating heatmap...'):
                if not options:
                    st.write('é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚')
                else:
                    corr_matrix = encoded_df[options].corr()
                    tab1_col1, tab1_col2 = st.columns(2)
                    
                    with tab1_col1:
                        plt.figure(figsize=(10, 8))
                        sns.heatmap(corr_matrix, annot=None, cmap='coolwarm', center=0,
                                    xticklabels=corr_matrix.columns, yticklabels=corr_matrix.index)
                        st.pyplot(plt)
                        plt.close() 

                    with tab1_col2:
                        st.dataframe(corr_matrix)
                        
                    corr_matrix_abs = corr_matrix.abs()
                    mask = np.triu(np.ones_like(corr_matrix_abs, dtype=bool))
                    tri_corr_matrix = corr_matrix_abs.where(mask)
                    np.fill_diagonal(tri_corr_matrix.values, np.nan)
                    sorted_corr = tri_corr_matrix.unstack().sort_values(ascending=False)
                    top_10_corr = sorted_corr.head(10)
                    
                    st.write("### Top 10")
                    st.dataframe(top_10_corr.reset_index(name='Correlation').rename(columns={'level_0': 'Feature1', 'level_1': 'Feature2'}))


    with tab4:
        st.header('ãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆ')

        st.write('å›³ãŒè¦‹ã«ãã„å ´åˆ,å‹•ä½œãŒé‡ã„å ´åˆã¯ç‰¹å¾´é‡ã‚’æ¸›ã‚‰ã—ã¦ã¿ã¦ãã ã•ã„ã€‚')

        options = st.multiselect(
            'ç‰¹å¾´é‡ã®é¸æŠ',
            features,
            features,
            key='pairplot_select_features'
        )

        if st.button('å®Ÿè¡Œ', key='unique_key_2'):
            with st.spinner('Generating graph...'):
                if len(options) < 2:
                    st.write('å°‘ãªãã¨ã‚‚ï¼’ã¤ä»¥ä¸Šã®é¸æŠè‚¢ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚')
                else:
                    df_subset = df_train[options].copy()

                    # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
                    le = LabelEncoder()
                    for col in options:
                        if df_subset[col].dtype == 'object':  # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                            df_subset[col] = le.fit_transform(df_subset[col])

                    # ç›®çš„å¤‰æ•°ã‚’`df_subset`ã«è¿½åŠ 
                    df_subset[target] = df_train[target]

                    # ãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆã®ç”Ÿæˆ
                    pairplot = sns.pairplot(df_subset, hue=target, palette='viridis', plot_kws={'alpha': 0.6}, corner=True)
                    st.pyplot(pairplot.figure)
                    plt.close()




# å„ç‰¹å¾´é‡ã®è¦ç´„---------------------
if choice == each_feature:

    dataset()
    feature_choice = st.sidebar.selectbox('ç‰¹å¾´é‡ã®é¸æŠ', [target] + features, index=0)

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®å–å¾—
    def get_unique_values(df, column):
        if column in df.columns:
            return df[column].unique()
        else:
            return []
    #ã€€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®è¡¨ç¤º    
    def display_values_with_quotes(values):
        quoted_values = [f"'{value}'" for value in values]
        return ', '.join(quoted_values)
    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    def plot_histogram_kde(df, feature_choice):
        bins = st.number_input('ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®ãƒ“ãƒ³ã®æ•°ã‚’è¨­å®š', min_value=5, max_value=1000, value=30, step=1, key=f'{df}_bins_{feature_choice}')
        with st.spinner('Generating graph...'):
            plt.figure(figsize=(10, 6))
            data = df[feature_choice].dropna()

            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            ax1 = plt.gca()
            ax1.hist(data, bins=bins, density=False, alpha=0.6, color='skyblue', edgecolor='black', label='Histogram')
            ax1.set_xlabel('Value')
            ax1.set_ylabel('Density', color='skyblue')
            ax1.tick_params(axis='y', labelcolor='skyblue')

            # KDE
            ax2 = ax1.twinx()
            kde = gaussian_kde(data, bw_method=0.3)
            x = np.linspace(data.min(), data.max(), 1000)
            ax2.plot(x, kde(x), color='red', label='KDE')
            ax2.set_ylabel('Density', color='red')
            ax2.tick_params(axis='y', labelcolor='red')

            # é‡ã­ã¦è¡¨ç¤º
            plt.title(f'{feature_choice} Histogram + KDE')
            ax1.grid(True)
            ax1.legend(loc='upper left')
            ax2.legend(loc='upper right')

            st.pyplot(plt)
            plt.clf()
    # ç®±ã²ã’å›³
    def plot_boxplot(df, feature_choice):
        plt.figure(figsize=(10, 6))
        plt.boxplot(df[feature_choice].dropna(), vert=False, patch_artist=True, 
                    boxprops=dict(facecolor='skyblue', color='black'), 
                    whiskerprops=dict(color='black'), 
                    medianprops=dict(color='red'))
        plt.title(f'{feature_choice} Box Plot')
        plt.xlabel('Value')
        plt.grid(True)
        
        st.pyplot(plt)
        plt.clf()
    # æ•£å¸ƒå›³
    def plot_scatter(df, feature_choice, target):
        plt.figure(figsize=(10, 6))
        plt.scatter(df[target], df[feature_choice], color='skyblue')
        plt.title(f'Scatter Plot of {target} and {feature_choice}')
        plt.xlabel(target)
        plt.ylabel(feature_choice)
        plt.grid(True)
        
        st.pyplot(plt)
        plt.clf() 
    # æ£’ã‚°ãƒ©ãƒ•
    def plot_bar_chart(df, feature_choice, chart_key):
        value_counts = df[feature_choice].value_counts().sort_values(ascending=False).reset_index()
        value_counts.columns = [feature_choice, 'Count']
        max_items = len(value_counts)
        num_items = st.slider(
            "è¡¨ç¤ºã™ã‚‹ç¯„å›²ã‚’æŒ‡å®š",
            min_value=1,
            max_value=max_items,
            value=min(10, max_items),
            key=f"slider_for_bar_chart_{chart_key}"
        )

        top_items = value_counts.head(num_items)

        plt.figure(figsize=(10, 6))
        sns.barplot(x=feature_choice, y='Count', data=top_items, palette='Blues_r')
        plt.title(f"Bar Chart of {feature_choice}")
        plt.xlabel('Category')
        plt.ylabel('Count')
        plt.xticks(rotation=45, ha='right')

        st.pyplot(plt)
        plt.clf()
    # ã‚¯ãƒ©ã‚¹å‰²åˆæ£’ã‚°ãƒ©ãƒ•
    def plot_target_ratio(df, feature_choice, target, chart_key):

        value_counts = df[feature_choice].value_counts().sort_values(ascending=False).reset_index()
        value_counts.columns = [feature_choice, 'Count']

        max_items = len(value_counts)
        num_items = st.slider(
            "è¡¨ç¤ºã™ã‚‹ç¯„å›²ã‚’æŒ‡å®š",
            min_value=1,
            max_value=max_items,
            value=min(10, max_items),
            key=f"slider_for_bar_chart_{chart_key}"
        )
        
        top_items = value_counts.head(num_items)[feature_choice].tolist()
        cross_table = pd.crosstab(df[feature_choice], df[target], normalize='index')
        
        top_items = [item for item in top_items if item in cross_table.index]
        sorted_cross_table = cross_table.loc[top_items]

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¯ãƒ©ã‚¹æ•°ã«å¿œã˜ã¦è‰²ã‚’è¨­å®š
        unique_classes = df[target].nunique()
        palette = sns.color_palette('Set3', unique_classes)  # 'husl' ãƒ‘ãƒ¬ãƒƒãƒˆã¯è‰²ã®åŒºåˆ¥ãŒã¯ã£ãã‚Šã™ã‚‹

        fig, ax = plt.subplots(figsize=(10, 6))
        sorted_cross_table.plot(kind='bar', stacked=True, ax=ax, color=palette)

        ax.set_title(f'{feature_choice} by {target} Ratio')
        ax.set_xlabel(f'{feature_choice}')
        ax.set_ylabel('Ratio')
        ax.set_xticks(range(len(sorted_cross_table.index)))
        ax.set_xticklabels(sorted_cross_table.index, rotation=45)
        ax.legend(title=target, loc='upper right')
        ax.grid(axis='y')

        st.pyplot(fig)
        plt.clf()
    #ãƒã‚¤ã‚ªãƒªãƒ³ãƒ—ãƒ­ãƒƒãƒˆ
    def violin_plot(df, feature, chart_key):
        value_counts = df[feature].value_counts()

        max_items = len(value_counts)
        num_items = st.slider(
            'è¡¨ç¤ºã™ã‚‹ç¯„å›²ã‚’æŒ‡å®š',
            min_value=1,
            max_value=max_items,
            value=min(10, max_items),
            key=f'slider_for_violin_plot_{chart_key}'
        )

        sorted_values_by_frequency = value_counts.sort_values(ascending=False).head(num_items).index
        filtered_df = df[df[feature].isin(sorted_values_by_frequency)]

        plt.figure(figsize=(10, 6))

        if df[feature].dtype == 'object':
            sns.violinplot(x=feature, y=target, data=filtered_df)
            plt.title(f'{feature} vs {target}')
        else:
            sns.violinplot(x=target, y=feature, data=filtered_df)
            plt.title(f'{feature} vs {target}')

        plt.xticks(rotation=45)
        st.pyplot(plt)
        plt.clf()

    #é‡çš„å¤‰æ•°ã®å‡¦ç†
    def numeric_feature(df_train, df_test, feature_choice):
        st.write(f'<h1 style="font-size: 24px;">{feature_choice} ã®è¦ç´„</h1>', unsafe_allow_html=True)
        st.markdown(
            f'**{feature_choice}**ã‚’**é‡çš„å¤‰æ•°**ã¨åˆ¤åˆ¥ã—ã¾ã—ãŸã€‚<br>'
            f'Dtypeã¯`{df_train[feature_choice].dtype}`ã§ã™ã€‚<br>'
            f'æ¬ æå€¤ã¯**{df_train[feature_choice].isnull().sum()}**å€‹ã‚ã‚Šã¾ã™ã€‚<br>',
            unsafe_allow_html=True
        )

        if feature_choice == target:
            plot_histogram_kde(df_train, feature_choice)
            st.markdown('<h3 style="font-size: 20px;">è¦ç´„çµ±è¨ˆé‡</h3>', unsafe_allow_html=True)
            st.dataframe(df_train[feature_choice].describe())
        
        else:
            st.markdown('<h3 style="font-size: 20px;">TrainDataã¨TestDataã®æ¯”è¼ƒ</h3>', unsafe_allow_html=True)

            con_hist_col1, con_hist_col2 = st.columns(2)
            with con_hist_col1:
                st.markdown('**TrainData**')
                plot_histogram_kde(df_train, feature_choice)
            with con_hist_col2:
                st.markdown('**TestData**')
                plot_histogram_kde(df_test, feature_choice)

            st.markdown('<h3 style="font-size: 20px;">ç›®çš„å¤‰æ•°ã¨ã®é–¢ä¿‚</h3>', unsafe_allow_html=True)

            vs_target_col1, vs_target_col2 = st.columns(2)
            with vs_target_col1:
                plt.figure(figsize=(10, 6))
                sns.violinplot(x=target, y=feature_choice, data=df_train)
                plt.title(f'{feature_choice} vs {target}')
                plt.xticks(rotation=0)
                st.pyplot(plt)
                plt.clf()
            with vs_target_col2:
                plot_scatter(df_train, feature_choice, target)

            st.markdown('<h3 style="font-size: 20px;">è¦ç´„çµ±è¨ˆé‡</h3>', unsafe_allow_html=True)
            st.dataframe(df_train[feature_choice].describe())

    #è³ªçš„å¤‰æ•°ã®å‡¦ç†
    def categorical_feature(df_train, df_test, feature_choice, max_display=10):
        st.write(f'<h1 style="font-size: 24px;">{feature_choice} ã®è¦ç´„</h1>', unsafe_allow_html=True)

        unique_values = df_train[feature_choice].unique()
        num_unique_values = len(unique_values)

        if num_unique_values > 20:
            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ãŒ20å€‹ã‚’è¶…ãˆã‚‹å ´åˆ
            displayed_values = list(map(str, unique_values[:max_display]))  # æœ€åˆã®max_displayå€‹ã‚’è¡¨ç¤º
            truncated_message = f"ï¼ˆ... ä»– {num_unique_values - max_display} å€‹ã®å€¤ãŒã‚ã‚Šã¾ã™ï¼‰"
            formatted_values = "', '".join(displayed_values) + truncated_message
        else:
            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ãŒ20å€‹ä»¥ä¸‹ã®å ´åˆ
            formatted_values = "', '".join(map(str, unique_values))

        st.markdown(
            f'''
            **{feature_choice}**ã‚’**è³ªçš„å¤‰æ•°**ã¨åˆ¤åˆ¥ã—ã¾ã—ãŸã€‚<br>
            Dtype : `{df_train[feature_choice].dtype}`<br>
            æ¬ æå€¤ : **{df_train[feature_choice].isnull().sum()}**å€‹<br>
            ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤({num_unique_values}å€‹) : <br>['{formatted_values}']<br><br>
            ''',
            unsafe_allow_html=True
        )

        if feature_choice == target:
            plot_bar_chart(df_train, feature_choice, '1')
        else:
            st.markdown('<h3 style="font-size: 20px;">TrainDataã¨TestDataã®æ¯”è¼ƒ</h3>', unsafe_allow_html=True)
            
            cat_plot_col1, cat_plot_col2 = st.columns(2)
            with cat_plot_col1:
                plot_bar_chart(df_train, feature_choice, '2')
            with cat_plot_col2:
                plot_bar_chart(df_test, feature_choice, '3')
            
            st.markdown('<h3 style="font-size: 20px;">ç›®çš„å¤‰æ•°ã¨ã®é–¢ä¿‚</h3>', unsafe_allow_html=True)
            vs_target_col1, vs_target_col2 = st.columns(2)
            with vs_target_col1:
                plot_target_ratio(df_train, feature_choice, target, '4')  # target ã‚’è¿½åŠ 
            
            st.markdown('<h3 style="font-size: 20px;">ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°</h3>', unsafe_allow_html=True)
            
            value_counts = df_train[feature_choice].value_counts()
            value_counts_df = value_counts.reset_index()
            value_counts_df.columns = ['Unique', 'UniqueCount']
            st.dataframe(value_counts_df)

    #æ™‚ç³»åˆ—å¤‰æ•°ã®å‡¦ç†
    def datatime_feature():
        st.write(f'<h1 style="font-size: 24px;">{feature_choice} ã®æ™‚ç³»åˆ—è¦ç´„</h1>', unsafe_allow_html=True)

    #ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä»»æ„ã®å¤‰æ•°å°ºåº¦ã«å¤‰æ›´ã—ãŸå ´åˆã®å‡¦ç†
    def select_type(index_num):
        select_type = st.sidebar.radio('å¤‰æ•°å°ºåº¦ã®å¤‰æ›´', ['é‡çš„å¤‰æ•°', 'è³ªçš„å¤‰æ•°'], index=index_num)
        if select_type == 'é‡çš„å¤‰æ•°':
            numeric_feature(df_train, df_test, feature_choice)
        elif select_type == 'è³ªçš„å¤‰æ•°':
            categorical_feature(df_train, df_test, feature_choice)

    # æ¬ æå€¤ã‚’é™¤å¤–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    cleaned_data = df_train[feature_choice].dropna()

    # é‡çš„å¤‰æ•°ã®æ¡ä»¶
    if pd.api.types.is_numeric_dtype(cleaned_data):
        # æ•°å€¤å‹ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ãŒ100æœªæº€ã®å ´åˆã¯ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã¨ã¿ãªã™
        if cleaned_data.nunique() < 50:
            select_type(1)  # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‡¦ç†
        else:
            select_type(0)  # é€£ç¶šçš„ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‡¦ç†

    # è³ªçš„å¤‰æ•°ã®æ¡ä»¶
    elif (
            pd.api.types.is_categorical_dtype(cleaned_data) or
            pd.api.types.is_string_dtype(cleaned_data) or
            cleaned_data.dtype == 'object'
        ):
        select_type(1)  # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‡¦ç†

    # æ™‚ç³»åˆ—å¤‰æ•°ã®æ¡ä»¶
    elif pd.api.types.is_datetime64_any_dtype(cleaned_data):
        select_type(2)  # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‡¦ç†

#ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰--------------------------
elif choice == model:

    dataset()
    df_sample = df_train.copy()
    st.write('LGBMã®åŸºæœ¬çš„ãªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ãƒ»å­¦ç¿’ãƒ»æ¤œè¨¼ã‚’ã—ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚')
    
    st.header("ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ãƒ»å­¦ç¿’ãƒ»äºˆæ¸¬")

    st.markdown('---')

    # ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã‚’é¸æŠ
    data_usage_rate = st.slider('ä½¿ç”¨ã™ã‚‹TrainDataã®å‰²åˆã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚', 0.0, 1.0, 1.0)
    data_usage_testrate = st.slider('TrainDataã®æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å‰²åˆã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚', 0.0, 1.0, 0.3)

    st.markdown('---')



    # ç›®çš„å¤‰æ•°ã®é¸æŠ
    target = st.selectbox(
        'ç›®çš„å¤‰æ•°ã®ç¢ºèª',
        [target]+features,
        index=0
    )

    # ç›®çš„å¤‰æ•°é¸æŠå¾Œã«ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’æ›´æ–°
    feature = [col for col in df_sample.columns if col != target]

    # ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã§ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠ
    model_feature_select = st.multiselect(
        'èª¬æ˜å¤‰æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚',
        options=features,
        default=features
    )

    st.markdown('---')

    purpose1 = 'å…¨ä½“çš„ãªæ­£è§£ç‡ã‚’è©•ä¾¡ã—ãŸã„'
    purpose2 = 'ãƒ¢ãƒ‡ãƒ«ã®å…¨ä½“çš„ãªãƒãƒ©ãƒ³ã‚¹ã‚’è©•ä¾¡ã—ãŸã„'
    purpose3 = 'å½é™½æ€§ã‚’æ¸›ã‚‰ã—ãŸã„'
    purpose4 = 'å½é™°æ€§ã‚’æ¸›ã‚‰ã—ãŸã„'
    purpose5 = 'ãƒ¢ãƒ‡ãƒ«ã®ç¢ºç‡äºˆæ¸¬ã®æ­£ç¢ºã•ã‚’è©•ä¾¡ã—ãŸã„'

    classification_select = st.selectbox(
        'ä½•ã‚’ç›®çš„ã¨ã—ã¾ã™ã‹ï¼Ÿ',
        [purpose1, purpose2, purpose5, purpose3, purpose4,]
    )
    
    value_counts = df_sample[target].value_counts(normalize=True)

    # æ¯”ç‡ã‚’æ•´æ•°æ¯”ã«å¤‰æ›ã™ã‚‹é–¢æ•°
    def compute_ratio(ratios):
        # æ¯”ç‡ã‚’æ•´æ•°ã«å¤‰æ›
        scale_factor = 1 / min(ratios)  # æœ€å°å€¤ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        int_ratios = [round(ratio * scale_factor) for ratio in ratios]
        # æœ€å¤§å…¬ç´„æ•°ã§å‰²ã‚‹
        def find_gcd(a, b):
            while b:
                a, b = b, a % b
            return a
        ratio_gcd = reduce(find_gcd, int_ratios)
        return [r // ratio_gcd for r in int_ratios]

    # æ¯”ç‡ã‚’è¨ˆç®—
    ratios = value_counts.values
    ratios_int = compute_ratio(ratios)
    labels = [f'{label}' for label in value_counts.index]

    # æ¯”ç‡ã®å·®ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®é–¢æ•°
    def categorize_ratio(ratios):
        max_ratio = max(ratios)
        min_ratio = min(ratios)
        ratio_diff = max_ratio / min_ratio
        
        if ratio_diff >= 10:
            return 'é«˜ã„æ¯”ç‡å·®'
        elif ratio_diff >= 5:
            return 'ä¸­ç¨‹åº¦ã®æ¯”ç‡å·®'
        elif 2<= ratio_diff < 5:
            return 'ä½ã„æ¯”ç‡å·®'
        else:
            return 'ã»ã¼å‡è¡¡'
        
    # æ¯”ç‡ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ±ºå®š
    ratio_category = categorize_ratio(ratios)

    # æ¯”ç‡ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    class_ratio = (f"ã‚¯ãƒ©ã‚¹æ¯”ç‡ã¯ {'ï¼š'.join(labels)} = {'ï¼š'.join(map(str, ratios_int))}ã§{ratio_category}")
    st.session_state.class_ratio = class_ratio

    if ratio_category == 'é«˜ã„æ¯”ç‡å·®':
        additional_metrics = ['ROC-AUC', 'F1', 'MCC']
        st.info(f'`{class_ratio}ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿é‡ã¨æ¯”è¼ƒã—ã¦ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãŒã¿ã‚‰ã‚Œã¾ã™ã€‚è©•ä¾¡æŒ‡æ¨™ROC-AUC,F1,MCCã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚`')
    else:
        additional_metrics = []
        st.write(f'`{class_ratio}ã§ã™ã€‚(ãƒ‡ãƒ¼ã‚¿é‡ã¨æ¯”è¼ƒã—ã¦ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãŒæ°—ã«ãªã‚‹å ´åˆè©•ä¾¡æŒ‡æ¨™ROC-AUC,F1,MCCã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚)`')

    st.write('ãŠã™ã™ã‚ã®è©•ä¾¡æŒ‡æ¨™')

    if classification_select == purpose1:
        eval_metric_default = ['Accuracy']
        
    elif classification_select == purpose2:
        eval_metric_default = ['F1', 'MCC']
        
    elif classification_select == purpose3:
        eval_metric_default = ['Precision']
        
    elif classification_select == purpose4:
        eval_metric_default = ['Recall']
    
    else:
        eval_metric_default = ['LogLoss']

    # è¿½åŠ ã®è©•ä¾¡æŒ‡æ¨™ã‚’åŠ ãˆã‚‹
    eval_metric_default.extend(additional_metrics)

    # çµæœã‚’è¡¨ç¤º
    if len(eval_metric_default) == 1:
        st.write(eval_metric_default[0])
    else:
        st.write(', '.join(eval_metric_default))

    eval_metric = st.multiselect(
        'è©•ä¾¡æŒ‡æ¨™ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚',
        options=['Accuracy', 'Precision', 'Recall', 'F1', 'LogLoss','ROC-AUC', 'MCC'],
        default=eval_metric_default
    )
    st.session_state.classification_eval_metric = eval_metric

    unique_classes = df_sample[target].unique()
    target_label_encoders = {}

    st.markdown('---')
    
    if len(unique_classes) == 2:
        # 2ã‚¯ãƒ©ã‚¹ã®å ´åˆã€é™½æ€§ãƒ©ãƒ™ãƒ«ã‚’é¸æŠã•ã›ã‚‹
        positive_label = st.radio('é™½æ€§ãƒ©ãƒ™ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„', options=unique_classes, key='positive_label_radio')
        negative_label = [cls for cls in unique_classes if cls != positive_label][0]
        
        # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ä½œæˆã—ã¦ä¿å­˜
        le = LabelEncoder()
        le.fit([negative_label, positive_label])
        target_label_encoders[target] = le
        # ãƒ©ãƒ™ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        df_sample[target] = df_sample[target].map({negative_label: 0, positive_label: 1})
        
    elif len(unique_classes) > 2:
        st.write('å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã®ãŸã‚è‡ªå‹•ã§ãƒ©ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦ã¾ã™ã€‚')

    else:
        st.warning("ã‚¯ãƒ©ã‚¹ãŒ1ã¤ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown('---')

    if st.button('å­¦ç¿’ãƒ»è©•ä¾¡'):

        with st.spinner('Learning...'):
            
            # é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            df_sample = df_sample.sample(frac=data_usage_rate, random_state=42)
            st.session_state.df_sample = df_sample
            
            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰(targetä»¥å¤–)
            label_encoders = {}
            for col in df_sample.columns:
                if df_sample[col].dtype == 'object' and col != target:
                    le = LabelEncoder()
                    df_sample[col] = le.fit_transform(df_sample[col])
                    label_encoders[col] = le
                                
            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’æº–å‚™
            X = df_sample[model_feature_select]
            y = df_sample[target]

            # ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=data_usage_testrate, random_state=42)

            # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
            model = lgb.LGBMClassifier()  # åˆ†é¡ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            # é€†å¤‰æ›ã‚’é©ç”¨ã™ã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            if target in target_label_encoders:
                le = target_label_encoders[target]
                y_test = le.inverse_transform(y_test)
                y_pred = le.inverse_transform(y_pred)
            # classification_reportã‚’ä½œæˆ
            report = classification_report(y_test, y_pred, output_dict=True)
            df_report = pd.DataFrame(report).transpose()

            #Accuracy
            accuracy = accuracy_score(y_test, y_pred)
            #Precision
            def precision(average):
                precision_ = {}
                precision_[average] = precision_score(y_test, y_pred, average=average)
                st.session_state[f'classification_precision_{average}'] = precision_[average]
                return precision_[average]
            precision_micro = precision('micro')
            precision_macro = precision('macro')
            precision_weighted = precision('weighted')
            precision = f"Precision || M**i**croAvg: {precision_micro:.4f}  |  M**a**croAvg: {precision_macro:.4f}  |  WeightedAvg: {precision_weighted:.4f}"
            #Recall
            def recall(average):
                recall_ = {}
                recall_[average] = recall_score(y_test, y_pred, average=average)
                st.session_state[f'classification_recall_{average}'] = recall_[average]
                return recall_[average]
            recall_micro = recall('micro')
            recall_macro = recall('macro')
            recall_weighted = recall('weighted')
            recall = f"Recall || M**i**croAvg: {recall_micro:.4f}  |  M**a**croAvg: {recall_macro:.4f}  |  WeightedAvg: {recall_weighted:.4f}"
            #F1
            def f1(average):
                f1_ = {}
                f1_[average] = f1_score(y_test, y_pred, average=average)
                st.session_state[f'classification_f1_{average}'] = f1_[average]
                return f1_[average]
            f1_micro = f1('micro')
            f1_macro = f1('macro')
            f1_weighted = f1('weighted')
            f1 = f"F1 || M**i**croAvg: {f1_micro:.4f}  |  M**a**croAvg: {f1_macro:.4f}  |  WeightedAvg: {f1_weighted:.4f}"
            #LogLoss
            y_proba = model.predict_proba(X_test)
            loss = log_loss(y_test, y_proba)
            #MCC
            mcc = matthews_corrcoef(y_test, y_pred)
            #ROC-AUC
            if len(unique_classes) == 2:
                positive_label = list(target_label_encoders[target].classes_)[1]
                negative_label = list(target_label_encoders[target].classes_)[0]
                y_test_binary = np.where(y_test == positive_label, 1, 0)
                y_proba = model.predict_proba(X_test)[:, 1] 
                roc_auc = roc_auc_score(y_test_binary, y_proba)
            elif len(unique_classes) > 2:
                y_proba = model.predict_proba(X_test)
                roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')

            def aprf(evaluation):
                if 0.9 <= evaluation:
                    st.markdown('`90%ä»¥ä¸Šã¯éå¸¸ã«è‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚`')
                elif 0.7 < evaluation < 0.9:
                    st.markdown('`70%~90%ã¯æ¯”è¼ƒçš„è‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚`')
                else:
                    st.markdown('`70%ä»¥ä¸‹ã¯ã‚ã¾ã‚Šè‰¯ã„æ€§èƒ½ã¨ã¯è¨€ãˆã¾ã›ã‚“ã€‚`')

            st.markdown(f'<h2 style="font-size: 24px;">è©•ä¾¡</h2>', unsafe_allow_html=True)
            if 'Accuracy' in eval_metric:
                st.info(f'âœ… Accuracy: {accuracy:.4f}')
                st.write('Acuuracy(æ­£è§£ç‡)ã¯å…¨ä½“ã®äºˆæ¸¬ãŒã©ã‚Œã ã‘æ­£ç¢ºã‹ç¤ºã—ã¾ã™ã€‚')
                aprf(accuracy)
            if 'Precision' in eval_metric:
                st.info('âœ… ' + precision)
                st.write('Precision(é©åˆç‡)ã¯é™½æ€§ã¨äºˆæ¸¬ã•ã‚ŒãŸä¸­ã§å®Ÿéš›ã«é™½æ€§ã§ã‚ã‚‹å‰²åˆã‚’ç¤ºã—ã¾ã™ã€‚å½é™½æ€§ã‚’æ¸›ã‚‰ã—ãŸã„å ´åˆã«é‡è¦ã§ã™ã€‚')
                aprf(precision_weighted)
            if 'Recall' in eval_metric:
                st.info('âœ… ' + recall)
                st.write('Recall(å†ç¾ç‡)ã¯å®Ÿéš›ã®é™½æ€§ã®ä¸­ã§æ­£ã—ãé™½æ€§ã¨äºˆæ¸¬ã•ã‚ŒãŸå‰²åˆã‚’ç¤ºã—ã¾ã™ã€‚å½é™°æ€§ã‚’æ¸›ã‚‰ã—ãŸã„å ´åˆã«é‡è¦ã§ã™ã€‚')
                aprf(recall_weighted)
            if 'F1' in eval_metric:
                st.info('âœ… ' + f1)
                st.write('F1ã¯Precisionã¨Recallã®èª¿å’Œå¹³å‡ã§ã™ã€‚ä¸¡è€…ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã™ã€‚')
                aprf(f1_weighted)
            if 'LogLoss' in eval_metric:
                st.info(f'âœ… Log Loss: {loss:.4f}')
                st.write('LogLossã¯ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸç¢ºç‡ã¨å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«ã¨ã®é–“ã®è·é›¢ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã§ã™ã€‚å°ã•ã„ã»ã©è‰¯ã„ã§ã™ã€‚')
                if 0.1 > loss:
                    st.markdown('`0.1ä»¥ä¸‹ã¯éå¸¸ã«è‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚`')
                elif 0.1<= loss <= 0.5:
                    st.markdown('`0.1~0.5ã¯æ¯”è¼ƒçš„è‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚`')
                else:
                    st.markdown('`0.5ä»¥ä¸Šã¯ã‚ã¾ã‚Šè‰¯ã„æ€§èƒ½ã¨ã¯è¨€ãˆã¾ã›ã‚“ã€‚`')
            if 'MCC' in eval_metric:
                st.info(f'âœ… MCC: {mcc:.4f}')
                st.write('MCC(ãƒã‚·ãƒ¥ãƒ¼ã‚ºç›¸é–¢ä¿‚æ•°)ã¯åˆ†é¡çµæœã®å…¨ä½“çš„ãªå“è³ªã‚’ç¤ºã™æŒ‡æ¨™ã§ã™ã€‚-1ã‹ã‚‰1ã®ç¯„å›²ã§ã€1ã¯å®Œç’§ãªåˆ†é¡ã‚’ç¤ºã—ã¾ã™ã€‚')
                aprf(mcc)
            if 'ROC-AUC' in eval_metric:
                if len(unique_classes) == 2:
                    st.info(f'âœ… ROC-AUC: {roc_auc:.4f}')
                    st.write('ROCæ›²ç·šã®ä¸‹ã®é¢ç©ã§ã™ã€‚ã‚¯ãƒ©ã‚¹ã®åˆ†é›¢èƒ½åŠ›ã‚’ç¤ºã—ã¾ã™ã€‚')
                    aprf(roc_auc)
                elif len(unique_classes) > 2:
                    st.info(f'âœ… ROC-AUC (One-vs-Rest): {roc_auc:.4f}')
                    st.write('ROCæ›²ç·šã®ä¸‹ã®é¢ç©ã§ã™ã€‚ã‚¯ãƒ©ã‚¹ã®åˆ†é›¢èƒ½åŠ›ã‚’ç¤ºã—ã¾ã™ã€‚')
                    aprf(roc_auc)                 

            st.markdown(f'<h2 style="font-size: 24px;">ãƒ¬ãƒãƒ¼ãƒˆ</h2>', unsafe_allow_html=True)
            st.markdown(f'**æ¦‚è¦**', unsafe_allow_html=True)
            st.markdown(
                f"""
                    {df_train.shape[0]}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’{int(data_usage_rate * 100)}%ã€ãã®å†…{int(data_usage_testrate * 100)}%ã‚’æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã—ãŸã€‚<br>
                    ç›®çš„å¤‰æ•°ã¯ {target}ã€‚ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã¯{df_train[target].unique()}ã§ã€{class_ratio}ã§ã™ã€‚<br>
                    èª¬æ˜å¤‰æ•°ã¯ä»¥ä¸‹ã®{len(model_feature_select)}å€‹ã§ã™ã€‚<br>
                    <br>
                    {model_feature_select}<br>
                    <br>
                    LGBMClassifierã‚’ä½¿ç”¨ã—ã¦åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚<br>
                    LGBMã‚’ä½¿ç”¨ã™ã‚‹ã«ã‚ãŸã‚Šã€æ–‡å­—åˆ—ã‚’scikit-learnã®LabelEncoderã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã—ãŸã€‚<br>
                    æ¬ æå€¤ã€å¤–ã‚Œå€¤ã€ç•°å¸¸å€¤ã®å‡¦ç†ã¯è¡Œã£ã¦ã„ã¾ã›ã‚“ã€‚<br>
                    <br>
                """, unsafe_allow_html=True)
            
            st.markdown(f'**è©•ä¾¡çµæœ**', unsafe_allow_html=True)
            st.write(f'Accuracy: {accuracy:.4f}')
            st.markdown(precision)
            st.markdown(recall)
            st.markdown(f1)
            st.write(f'Log Loss: {loss:.4f}')
            st.write(f'MCC: {mcc:.4f}')
            if len(unique_classes) == 2:
                st.write(f'ROC-AUC: {roc_auc:.4f}')
            elif len(unique_classes) > 2:
                st.write(f'ROC-AUC (One-vs-Rest): {roc_auc:.4f}')
            
            st.markdown(f'<br>**æ··åŒè¡Œåˆ— / äºˆæ¸¬ç¢ºç«‹ / ROCæ›²ç·š**', unsafe_allow_html=True)                
            report1_col1, report1_col2, report1_col3 = st.columns(3)
            with report1_col1:
                def cm():
                    cm = confusion_matrix(y_test, y_pred)
                    plt.figure(figsize=(8, 6))  # ã‚µã‚¤ã‚ºã‚’æŒ‡å®š
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_classes, yticklabels=unique_classes)
                    plt.xlabel('Predicted labels')
                    plt.ylabel('True labels')
                    plt.title('Confusion Matrix')
                    st.pyplot(plt)
                    plt.clf()

                cm()

            with report1_col2:
                if len(unique_classes) == 2:
                    # äºŒå€¤åˆ†é¡ã®å ´åˆã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
                    plt.figure(figsize=(10, 6))
                    plt.hist(y_proba, bins=20, color='skyblue', edgecolor='black')
                    plt.xlabel('Predicted Probability')
                    plt.ylabel('Frequency')
                    plt.title('Histogram of Predicted Probabilities')
                    st.pyplot(plt)
                    plt.clf()

                if len(unique_classes) > 2:
                    plt.figure(figsize=(10, 6))
                    df_proba = pd.DataFrame(y_proba, columns=[f'{cls}' for cls in unique_classes])
                    df_proba_melted = df_proba.melt(var_name='Class', value_name='Predicted Probability')
                    
                    sns.violinplot(x='Class', y='Predicted Probability', data=df_proba_melted, palette='viridis')
                    
                    plt.xlabel('Class')
                    plt.xticks(rotation=90)
                    plt.ylabel('Predicted Probability')
                    plt.title('Violin Plot of Predicted Probabilities by Class')
                    st.pyplot(plt)
                    plt.clf()
                
            with report1_col3:
                if len(unique_classes) == 2:
                    positive_label = list(target_label_encoders[target].classes_)[1]
                    y_test_binary = np.where(y_test == positive_label, 1, 0)
                    y_proba = model.predict_proba(X_test)[:, 1]
                    
                    # ROCæ›²ç·šã®è¨ˆç®—
                    fpr, tpr, _ = roc_curve(y_test_binary, y_proba)
                    roc_auc = auc(fpr, tpr)
                    
                    # ROCæ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
                    plt.figure(figsize=(10, 7))
                    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
                    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
                    plt.xlim([0.0, 1.0])
                    plt.ylim([0.0, 1.05])
                    plt.xlabel('False Positive Rate')
                    plt.ylabel('True Positive Rate')
                    plt.title('Receiver Operating Characteristic')
                    plt.legend(loc='lower right')
                    st.pyplot(plt)
                    plt.clf()
                
                # å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã®å ´åˆ
                if len(unique_classes) > 2:
                    y_test_bin = label_binarize(y_test, classes=unique_classes)
                    y_proba = model.predict_proba(X_test)
                    
                    plt.figure(figsize=(10, 7))
                    for i in range(len(unique_classes)):
                        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])
                        roc_auc = auc(fpr, tpr)
                        plt.plot(fpr, tpr, lw=2, label='ROC curve of class {0} (area = {1:0.2f})'.format(unique_classes[i], roc_auc))

                    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
                    plt.xlim([0.0, 1.0])
                    plt.ylim([0.0, 1.05])
                    plt.xlabel('False Positive Rate')
                    plt.ylabel('True Positive Rate')
                    plt.title('Receiver Operating Characteristic - Multi-class')
                    plt.legend(loc='lower right')
                    st.pyplot(plt)
                    plt.clf()

            st.markdown(
                f"""
                ã”è‡ªèº«ã®ã‚¿ã‚¹ã‚¯ã€ä»–ã®æŒ‡æ¨™ã¨æ¯”ã¹ã¦æ€§èƒ½ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚<br>
                ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ã§ã•ã‚‰ã«æ€§èƒ½ãŒä¸ŠãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚<br>
                è©•ä¾¡ã—ãŸã„æŒ‡æ¨™ãŒé«˜ã„å ´åˆã§ã‚‚ã€äº¤å·®æ¤œè¨¼ã‚’è¡Œã„æ€§èƒ½ã®å®‰å®šæ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚<br>
                è©•ä¾¡ã—ãŸã„æŒ‡æ¨™ãŒä½ã„å ´åˆã€LGBMä»¥å¤–ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚<br>
                """, unsafe_allow_html=True)
            
            st.markdown(f'<br>**ç‰¹å¾´é‡é‡è¦åº¦ / ç›¸é–¢ä¿‚æ•°TOP5**', unsafe_allow_html=True)
            
            feature_importance_col1, feature_importance_col2 = st.columns(2)
            with feature_importance_col1:
                # ç‰¹å¾´é‡é‡è¦åº¦ã®å–å¾—ã¨è¡¨ç¤º
                feature_importances = model.feature_importances_
                importance_df = pd.DataFrame({
                    'Feature': model_feature_select,
                    'Importance': feature_importances
                }).sort_values(by='Importance', ascending=False)
                
                st.write("ç‰¹å¾´é‡é‡è¦åº¦")
                plt.figure(figsize=(10, 6))
                plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
                plt.xlabel('Importance')
                plt.ylabel('Feature')
                plt.title('Feature Importance')
                plt.gca().invert_yaxis()  # é™é †ã«ä¸¦ã¹ã‚‹
                st.pyplot(plt)
                plt.clf()

            with feature_importance_col2:
                corr_matrix = df_sample[model_feature_select].corr()

                # ç›¸é–¢ä¿‚æ•°ã®ä¸Šä½5ã¤ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®é–¢æ•°
                def get_top_correlations(corr_matrix, top_n=5):
                    # ä¸Šä¸‰è§’è¡Œåˆ—ã‚’ãƒã‚¹ã‚¯
                    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
                    # ç›¸é–¢ä¿‚æ•°ã‚’ãƒã‚¹ã‚¯ã—ã€ã‚¹ã‚¿ãƒƒã‚¯ã—ã¦Seriesã«å¤‰æ›
                    corr_stack = corr_matrix.where(~mask).stack()
                    # çµ¶å¯¾å€¤ã§ã‚½ãƒ¼ãƒˆã—ã€ä¸Šä½5ã¤ã‚’å–å¾—
                    top_correlations = corr_stack.abs().nlargest(top_n)
                    # ä¸Šä½5ã¤ã®ç›¸é–¢ä¿‚æ•°ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                    df_top_corr = top_correlations.reset_index()
                    df_top_corr.columns = ['Feature1', 'Feature2', 'Correlation']
                    return df_top_corr

                # ä¸Šä½5ã¤ã®ç›¸é–¢ä¿‚æ•°ã‚’å–å¾—
                st.write("ç›¸é–¢ä¿‚æ•°TOP5")
                top_5_corr = get_top_correlations(corr_matrix, top_n=5)

                top_5_corr

            st.markdown(
                f"""
                ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‹ã‚‰ä¸Šè¨˜ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’å¾—ã‚‰ã‚Œã¾ã—ãŸã€‚<br>
                ç›¸é–¢ä¿‚æ•°ã®é«˜ã„çµ„ã¿åˆã‚ã›ã¨åˆã‚ã›ã¦ã©ã®ç‰¹å¾´é‡ã‚’æ·±å €ã™ã‚‹ã‹æ¤œè¨ã—ã€å‰å‡¦ç†ãƒ»ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
                """, unsafe_allow_html=True)     
            
    else:
        pass
#-----------------------------------
else:
    pass